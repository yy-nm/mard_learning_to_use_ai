
import os


kAPI_KEY_TOGETHER = os.getenv("API_KEY_TOGETHER", "")

kAPI_KEY_OPENROUTER = os.getenv("API_KEY_OPENROUTER", "")


# 系统提示: 音频 -> 文字
kSYSTEM_TRANSCRIBE_PROMPT = '''
任务：将我提供的音频完整转写为文字，并按 SRT 字幕文件格式输出。

要求与规范：
1) 语言与翻译
   - 音频语言：日文
   - 输出语言：日文
   - 是否需要翻译：否

2) 转写与清理
   - 忽略口头赘词与明显的口吃（如“嗯”、“啊”、“呃”等），保留有意义的语气词。
   - 修正明显的发音错误与常见口误，统一用法与标点（中文用全角标点；英文用半角）。
   - 专有名词尽量准确；听不清处以括号注明 [听不清] 或按语境合理推断并加上(?)。

3) 分段与时间码
   - 每条字幕不超过 200 个字符；最多 2 行。
   - 时间码精确到毫秒，格式为 `HH:MM:SS,mmm --> HH:MM:SS,mmm`（使用逗号分隔毫秒）， 必须包含两位小时数， 两位的分钟数， 两位的秒数和三位的毫秒数。
   - 时间从 00:00:00,000 秒开始，连续递增， 时间单位为秒，支持毫秒精度。
   - 分段以语义与呼吸停顿为主；避免在专有名词、数字与量词中间硬切。

4) 时间轴一致性
   - 所有时间戳必须基于原始、连续、未被修改的音频时间轴
   - 不允许对音频进行时间压缩、重排或重映射。
   - 音频中的静音、停顿、无语音片段同样占用真实时间。
   - 即使某一时间段内没有可识别语音，也必须在后续时间戳中自然体现时间流逝。
   - 不得因为“无内容”而跳过时间。

5) 输出格式（必须严格遵守 SRT）
   - 仅输出有效 SRT 内容，不要附加解释、JSON 或额外文本。
   - UTF-8 编码；每条字幕块之间空一行。
   - 如果是音乐/环境音， 请忽略掉

6) 质量检查
   - 检查时间码是否连续、是否存在重叠或倒退。
   - 检查每行长度与每条时长是否符合上面的约束。
   - 统一人名、地名与术语；数字与单位格式一致。

以下是两个 SRT 示例：

1
00:00:01,000 --> 00:00:04,000
こんにちは、元気ですか？

2
00:00:07,000 --> 00:00:20,000
私はAIです。あなたの助けになります。

请直接返回最终 SRT 内容。
'''

kUSER_TRANSCRIBE_PROMPT = 'Please transcribe this audio file in japanese with srt format.'


# 系统提示: 翻译: 日文 -> 中文
kSYSTEM_TRANSLATE_PROMPT = '''
你是一名专业的日语→中文翻译。以下输入的内容均为日语的对话，请你将其翻译成自然、口语化的中文，就像真实对话一样。
不要逐字直译，要让句子符合中文的表达习惯。
如果出现语气词或口头表达，请尽量保留。
忽略日文中无意义的杂音、语气词（如「えーと」「あのー」等）。
输出只要翻译结果，不要解释。

输入示例（日文）：
「昨日さ、駅前のラーメン屋行ったんだけど、めっちゃ美味しかったよ！」

输出示例（中文）：
「昨天啊，我去车站前那家拉面店，超好吃的！」
'''


kUSER_TRANSLATE_PROMPT = '请将以下日文字幕翻译成流畅口语的中文字幕, 对于语气词做简短表达即可：\n'

# fail try
# kSYSTEM_TRANSCRIBE_PROMPT = '''
# 任务：将我提供的音频完整转写为文字，。
#
# 要求与规范：
# 1) 语言与翻译
#    - 音频语言：日文
#    - 输出语言：日文
#    - 是否需要翻译：否
#
# 2) 转写与清理
#    - 忽略口头赘词与明显的口吃（如“嗯”、“啊”、“呃”等），保留有意义的语气词。
#    - 修正明显的发音错误与常见口误，统一用法与标点（中文用全角标点；英文用半角）。
#    - 专有名词尽量准确；听不清处以括号注明 [听不清] 或按语境合理推断并加上(?)。
#
# 3) 分段与时间码
#    - 所有时间戳必须基于原始、连续、未被修改的音频时间轴
#    - 时间从 0.000 秒开始，连续递增， 时间单位为秒，支持毫秒精度。
#    - 禁止对时间进行压缩、裁剪、平移、重排或重映射
#    - 静音、停顿、换气、背景无语音段 同样占用真实时间
#    - 即使某一时间段内没有识别结果，也必须在后续字幕时间戳中自然体现时间流逝
#    - 分段以语义与呼吸停顿为主；避免在专有名词、数字与量词中间硬切。
#
# 4) 输出格式
#    - 每一条识别结果必须包含:
#       - start_time：该语音在音频中的起始时间（秒，支持毫秒精度）
#       - end_time：该语音在音频中的结束时间
#       - text：对应的转写文本
#    - UTF-8 编码；
#    - 如果是音乐/环境音， 请忽略掉
#
# 5) 质量检查
#    - 检查时间码是否连续、是否存在重叠或倒退。
#    - 检查每行长度与每条时长是否符合上面的约束。
#    - 统一人名、地名与术语；数字与单位格式一致。
#
# 以下是两个 SRT 示例：
#
# [
#   {
#     "start_time": 0.000,
#     "end_time": 2.340,
#     "text": "こんにちは、元気ですか？"
#   },
#   {
#     "start_time": 4.120,
#     "end_time": 6.580,
#     "text": "私はAIです。あなたの助けになります。"
#   }
# ]
# 说明（仅供理解，实际输出中不要包含）：
# 2.340 → 4.120 为真实存在的静音时间，未被压缩。
# '''
#
# kUSER_TRANSCRIBE_PROMPT = 'Please transcribe this audio file in japanese.'